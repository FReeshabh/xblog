{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A traditional yet actual intro to ML (with code!, from scratch!)\n",
    "\n",
    "In this tutorial, we'll be looking at the baby stuff for ML, which will be Linear Regression. But we'll look into implementing it from scratch. So we're not going to use any Machine Learning Libraries. \n",
    "The only library use for the actual Regression part of this will be numpy (refer to [CS 231N's excellent notes](https://cs231n.github.io/python-numpy-tutorial/#numpy), for a quick intro). This tutorial contains code from Python, so I expect a bit of familiarity with how Python works, if not check the link above for a quick intro. \n",
    "\n",
    "***Prereqs and what we need:***\n",
    "1. High School Math\n",
    "2. A tiny bit of linear algebra\n",
    "3. Python Knowledge\n",
    "    - Numpy (For computation)\n",
    "    - Matplotlib (For graphing our results)\n",
    "    - pandas (to read our file)\n",
    "\n",
    "**What we'll do:**\n",
    "\n",
    "1. Implement a Closed Form Solution for the simplest of Linear Regressions\n",
    "2. What we did earlier, but now using Gradient Descent\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/proj1-dataset/proj1Dataset.csv\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepping the data\n",
    "Here we're reading our dataset. The dataset I'm using for this project is the carbig dataset, that's already available in Matlab, this dataset is relatively simple and the description here says: Measurements of cars, 1970â€“1982[](http://)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "",
    "_uuid": ""
   },
   "outputs": [],
   "source": [
    "proj1Dataset = pd.read_csv(\"../input/proj1-dataset/proj1Dataset.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we apply Linear regression to this right? Actually not just yet. We need to take out the data from our dataset and make it usable. We also see it's missing a few values in the Horsepower column. So we have to deal with that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'carbig_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-91fd4f4532fb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Assign Data to variables\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcarbig_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Weight'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mcarbig_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Horsepower'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcarbig_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Horsepower'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfillna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcarbig_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Horsepower'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmedian\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#Replacing missing values with the median\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mt_target\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcarbig_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Horsepower'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'carbig_data' is not defined"
     ]
    }
   ],
   "source": [
    "# Assign Data to variables\n",
    "X = carbig_data['Weight']\n",
    "carbig_data['Horsepower'] = carbig_data['Horsepower'].fillna(carbig_data['Horsepower'].median()) #Replacing missing values with the median\n",
    "t_target = carbig_data['Horsepower']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So in the previous step, we took care of the missing values by replacing them with the median of the Horsepower column. And assigned our X and t variables. X is basically like the X axis you see in Math Textbooks, and T will be our target, or just like the y axis you see in Math Textbooks. (Keep in mind, we're not using a test dataset in this tutorial - to know what that means please check [this](https://developers.google.com/machine-learning/crash-course/training-and-test-sets/splitting-data) )\n",
    "\n",
    "*So now we apply Linear Regression right?* Nope not yet, if you carefully check the np arrays we store the data in (Hint: check the [shape](https://docs.scipy.org/doc/numpy/reference/generated/numpy.ndarray.shape.html)) You'll realize that we actually can't use this data. Because it's not in the shape we want it to be for the Multiplication that's coming soon! So, we need to reshape it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-e8b58bd712ad>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Reshape and prep X, and X_norm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;31m#X_norm = np.empty(X.shape) #What are these (Look up Normalization, but we'll get back to these)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#X_norm = X/X.max()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mt_target\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_target\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X' is not defined"
     ]
    }
   ],
   "source": [
    "# Reshape and prep X, and X_norm\n",
    "X = np.reshape(X.values, (-1, 1))\n",
    "#X_norm = np.empty(X.shape) #What are these (Look up Normalization, but we'll get back to these)\n",
    "#X_norm = X/X.max()\n",
    "t_target = np.reshape(t_target.values, (-1, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Incomplete .. Wait for the update]\n",
    "Busy with school work, it will be updated soon, don't worry"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
